{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89aaa5b2-0ab5-451f-aa1b-66d6ff4bf444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:12:49.429551Z",
     "iopub.status.busy": "2023-05-18T17:12:49.429401Z",
     "iopub.status.idle": "2023-05-18T17:24:36.749509Z",
     "shell.execute_reply": "2023-05-18T17:24:36.748970Z",
     "shell.execute_reply.started": "2023-05-18T17:12:49.429536Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy trainscript failed\n",
      "Data files:\n",
      "['/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile1.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile2.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile3.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile4.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile5.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile6.nc']\n",
      "Data selection:\n",
      "    Month: [1, 4, 7, 12] \n",
      "    Day: [1] \n",
      "Reading data... 0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Features| Input: 106,  Output: 36\n",
      "Total data size: 1769472\n",
      "Night time will be removed! (rsdt==0)\n",
      "Total data size (daylight): (1055384,)\n",
      "Total data size: 1055384\n",
      "Test data ratio: 0.3\n",
      "Train info >> run: 1 lr_sta: 1.0e-03, batch size: 8000\n",
      "Epoch 000001 |Train L: 1.94e-01 2.15e+01 | Vali. L: 2.14e-01 3.26e+01  | ~   0s | eta   0 min\n",
      "Epoch 000201 |Train L: 7.14e-03 8.85e-01 | Vali. L: 5.64e-03 5.29e-01  | ~  49s | eta   7 min\n",
      "Epoch 00210: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 00369: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 000401 |Train L: 1.95e-03 1.77e-01 | Vali. L: 1.65e-03 1.69e-01  | ~  48s | eta   6 min\n",
      "Epoch 00537: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 000601 |Train L: 1.18e-03 1.53e-01 | Vali. L: 1.45e-03 1.24e-01  | ~  48s | eta   5 min\n",
      "Epoch 00638: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 00739: reducing learning rate of group 0 to 3.2000e-07.\n",
      "Epoch 000801 |Train L: 2.13e-03 7.27e-02 | Vali. L: 1.48e-03 1.14e-01  | ~  48s | eta   4 min\n",
      "Epoch 00840: reducing learning rate of group 0 to 6.4000e-08.\n",
      "Epoch 00941: reducing learning rate of group 0 to 1.2800e-08.\n",
      "Epoch 001001 |Train L: 1.14e-03 1.68e-01 | Vali. L: 1.42e-03 1.33e-01  | ~  48s | eta   4 min\n",
      "Meet early stop criteria LR = 1.2800000000000007e-08 < 1e-7\n",
      "End training\n",
      "Epoch 000001 |Train L: 1.76e-01 2.30e+01 | Vali. L: 1.97e-01 2.96e+01  | ~   0s | eta   0 min\n",
      "Epoch 000201 |Train L: 3.45e-03 3.82e-01 | Vali. L: 6.37e-03 4.24e-01  | ~  48s | eta   7 min\n",
      "Epoch 00227: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 00362: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 000401 |Train L: 3.26e-03 3.30e-01 | Vali. L: 1.64e-03 8.98e-02  | ~  48s | eta   6 min\n",
      "Epoch 000601 |Train L: 3.31e-03 5.44e-02 | Vali. L: 1.55e-03 7.03e-02  | ~  48s | eta   5 min\n",
      "Epoch 00745: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 000801 |Train L: 1.14e-03 2.05e-01 | Vali. L: 1.35e-03 6.59e-02  | ~  48s | eta   4 min\n",
      "Epoch 00870: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 00981: reducing learning rate of group 0 to 3.2000e-07.\n",
      "Epoch 001001 |Train L: 1.33e-03 3.37e-01 | Vali. L: 1.35e-03 6.37e-02  | ~  49s | eta   4 min\n",
      "Epoch 01131: reducing learning rate of group 0 to 6.4000e-08.\n",
      "Epoch 001201 |Train L: 1.32e-03 2.25e-01 | Vali. L: 1.37e-03 6.87e-02  | ~  49s | eta   3 min\n",
      "Meet early stop criteria LR = 6.400000000000003e-08 < 1e-7\n",
      "End training\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.01.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([1.4490, 1.1558, 1.4393, 0.2767, 0.1651, 0.0945, 0.0586, 0.0389, 0.0272,\n",
      "        0.0202, 0.0144, 0.0100, 0.0073, 0.0064, 0.0061, 0.0073, 0.0104, 0.0125,\n",
      "        0.0143, 0.0148, 0.0156, 0.0167, 0.0177, 0.0176, 0.0178, 0.0186, 0.0208,\n",
      "        0.0206, 0.0162, 0.0158, 0.0156, 0.0192, 0.0195, 0.0206, 0.0196, 0.0204]) \n",
      " tensor([0.8391, 0.8782, 0.8194, 0.1463, 0.0876, 0.0563, 0.0389, 0.0256, 0.0180,\n",
      "        0.0125, 0.0089, 0.0063, 0.0044, 0.0037, 0.0039, 0.0048, 0.0067, 0.0081,\n",
      "        0.0090, 0.0095, 0.0101, 0.0106, 0.0108, 0.0105, 0.0107, 0.0107, 0.0109,\n",
      "        0.0107, 0.0091, 0.0085, 0.0082, 0.0088, 0.0083, 0.0083, 0.0080, 0.0085]) \n",
      " tensor([ 2.4864e-01,  6.0216e-01,  1.9914e-01,  9.3708e-02,  2.8676e-03,\n",
      "         1.1517e-02,  1.2469e-02,  6.9216e-03,  5.1532e-03,  5.3681e-03,\n",
      "         3.5297e-03,  1.9746e-03,  1.2533e-03,  1.0295e-03,  5.9169e-04,\n",
      "         2.4795e-04,  1.4446e-03,  1.6385e-03,  1.2680e-03,  1.3117e-03,\n",
      "         2.3918e-03,  3.9244e-03,  3.5949e-03,  1.1029e-03,  3.2433e-03,\n",
      "         2.2748e-03,  3.3994e-03,  4.2458e-03,  1.9934e-03,  1.8185e-03,\n",
      "         1.1601e-03,  1.6154e-03,  1.1537e-04, -1.7155e-04,  6.5191e-04,\n",
      "         8.9479e-04])\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.01.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([1.4677, 1.1225, 1.5309, 0.2742, 0.1053, 0.0733, 0.0508, 0.0353, 0.0253,\n",
      "        0.0251, 0.0196, 0.0098, 0.0056, 0.0053, 0.0052, 0.0068, 0.0107, 0.0123,\n",
      "        0.0129, 0.0134, 0.0179, 0.0151, 0.0161, 0.0156, 0.0167, 0.0174, 0.0158,\n",
      "        0.0169, 0.0217, 0.0148, 0.0143, 0.0138, 0.0142, 0.0186, 0.0222, 0.0227]) \n",
      " tensor([0.8093, 0.8969, 0.7996, 0.1205, 0.0664, 0.0477, 0.0333, 0.0230, 0.0158,\n",
      "        0.0118, 0.0087, 0.0056, 0.0037, 0.0032, 0.0033, 0.0044, 0.0066, 0.0079,\n",
      "        0.0084, 0.0086, 0.0103, 0.0094, 0.0098, 0.0096, 0.0100, 0.0101, 0.0095,\n",
      "        0.0096, 0.0098, 0.0083, 0.0078, 0.0074, 0.0072, 0.0075, 0.0078, 0.0081]) \n",
      " tensor([2.3713e-01, 7.4435e-01, 2.2152e-01, 6.0835e-02, 1.2902e-02, 1.6736e-02,\n",
      "        1.0233e-02, 4.5552e-03, 4.9910e-03, 5.5647e-03, 3.8392e-03, 2.1047e-03,\n",
      "        1.0897e-03, 1.1358e-03, 8.4009e-04, 1.3910e-03, 1.9578e-03, 2.6720e-03,\n",
      "        2.0749e-03, 1.2297e-03, 1.3205e-03, 6.5718e-04, 1.1545e-03, 1.4331e-03,\n",
      "        3.0852e-03, 1.7740e-03, 2.5784e-03, 4.0053e-03, 2.1349e-03, 3.3781e-03,\n",
      "        3.0630e-03, 2.8640e-03, 3.0044e-03, 1.1210e-03, 1.1245e-03, 2.1048e-03])\n",
      "ens_AM4std_sw_cs_LiH4W256Relu_EY Finished: run 1!\n",
      "Train info >> run: 2 lr_sta: 1.0e-04, batch size: 32000\n",
      "Epoch 000001 |Train L: 1.97e-03 8.62e-02 | Vali. L: 1.68e-03 1.48e-01  | ~   0s | eta   0 min\n",
      "Epoch 00093: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Epoch 000201 |Train L: 3.10e-03 9.21e-02 | Vali. L: 1.28e-03 1.16e-01  | ~  18s | eta   2 min\n",
      "Epoch 00322: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 000401 |Train L: 1.11e-03 8.79e-02 | Vali. L: 1.17e-03 1.06e-01  | ~  18s | eta   2 min\n",
      "Epoch 00423: reducing learning rate of group 0 to 8.0000e-07.\n",
      "Epoch 00524: reducing learning rate of group 0 to 1.6000e-07.\n",
      "Epoch 000601 |Train L: 1.14e-03 1.66e-01 | Vali. L: 1.18e-03 1.02e-01  | ~  18s | eta   2 min\n",
      "Epoch 00625: reducing learning rate of group 0 to 3.2000e-08.\n",
      "Epoch 00726: reducing learning rate of group 0 to 6.4000e-09.\n",
      "Epoch 000801 |Train L: 1.77e-03 6.93e-01 | Vali. L: 1.20e-03 1.11e-01  | ~  18s | eta   1 min\n",
      "Meet early stop criteria LR = 6.4000000000000035e-09 < 1e-7\n",
      "End training\n",
      "Epoch 000001 |Train L: 1.82e-03 2.73e-01 | Vali. L: 1.73e-03 7.75e-02  | ~   0s | eta   0 min\n",
      "Epoch 00056: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Epoch 00200: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 000201 |Train L: 1.95e-03 1.64e-01 | Vali. L: 1.22e-03 6.12e-02  | ~  18s | eta   2 min\n",
      "Epoch 00301: reducing learning rate of group 0 to 8.0000e-07.\n",
      "Epoch 000401 |Train L: 2.10e-03 8.17e-02 | Vali. L: 1.23e-03 6.09e-02  | ~  18s | eta   2 min\n",
      "Epoch 00402: reducing learning rate of group 0 to 1.6000e-07.\n",
      "Epoch 00542: reducing learning rate of group 0 to 3.2000e-08.\n",
      "Epoch 000601 |Train L: 1.08e-03 8.72e-02 | Vali. L: 1.23e-03 5.97e-02  | ~  18s | eta   2 min\n",
      "Meet early stop criteria LR = 3.2000000000000015e-08 < 1e-7\n",
      "End training\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.02.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([1.3800, 1.1225, 1.3923, 0.2602, 0.1665, 0.0979, 0.0564, 0.0366, 0.0255,\n",
      "        0.0193, 0.0137, 0.0094, 0.0069, 0.0060, 0.0059, 0.0072, 0.0102, 0.0126,\n",
      "        0.0139, 0.0144, 0.0149, 0.0161, 0.0177, 0.0168, 0.0175, 0.0183, 0.0191,\n",
      "        0.0192, 0.0159, 0.0152, 0.0151, 0.0181, 0.0175, 0.0187, 0.0185, 0.0192]) \n",
      " tensor([0.7652, 0.8583, 0.7627, 0.1338, 0.0828, 0.0545, 0.0367, 0.0240, 0.0167,\n",
      "        0.0115, 0.0082, 0.0058, 0.0041, 0.0034, 0.0037, 0.0047, 0.0067, 0.0083,\n",
      "        0.0088, 0.0092, 0.0096, 0.0100, 0.0106, 0.0102, 0.0105, 0.0104, 0.0105,\n",
      "        0.0103, 0.0090, 0.0083, 0.0080, 0.0084, 0.0078, 0.0078, 0.0077, 0.0081]) \n",
      " tensor([-1.8081e-02,  6.0183e-01, -4.7391e-02,  7.5345e-02,  4.6716e-04,\n",
      "         9.4787e-03,  9.6074e-03,  4.2241e-03,  2.3476e-03,  2.7844e-03,\n",
      "         1.6166e-03,  8.3473e-04,  3.9908e-04,  5.5196e-04,  6.1949e-04,\n",
      "         1.3355e-03,  2.8727e-03,  3.4923e-03,  2.1724e-03,  7.0304e-04,\n",
      "         1.7332e-03,  2.5528e-03,  2.9467e-03,  2.7888e-03,  4.0880e-03,\n",
      "         1.8990e-03,  3.6146e-03,  4.3484e-03,  2.4592e-03,  2.4815e-03,\n",
      "         1.6697e-03,  1.5934e-03,  6.5876e-04,  2.4435e-04,  7.6366e-04,\n",
      "         9.0224e-04])\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.02.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([1.3998, 1.0459, 1.4496, 0.3327, 0.1072, 0.0780, 0.0511, 0.0342, 0.0248,\n",
      "        0.0250, 0.0194, 0.0096, 0.0055, 0.0051, 0.0051, 0.0068, 0.0106, 0.0124,\n",
      "        0.0128, 0.0134, 0.0185, 0.0152, 0.0163, 0.0154, 0.0159, 0.0172, 0.0158,\n",
      "        0.0165, 0.0223, 0.0143, 0.0137, 0.0136, 0.0142, 0.0191, 0.0226, 0.0235]) \n",
      " tensor([0.7742, 0.8330, 0.7601, 0.1198, 0.0655, 0.0477, 0.0328, 0.0224, 0.0153,\n",
      "        0.0114, 0.0084, 0.0054, 0.0036, 0.0031, 0.0033, 0.0044, 0.0065, 0.0080,\n",
      "        0.0083, 0.0086, 0.0103, 0.0096, 0.0099, 0.0094, 0.0096, 0.0098, 0.0094,\n",
      "        0.0093, 0.0094, 0.0078, 0.0073, 0.0070, 0.0070, 0.0074, 0.0076, 0.0079]) \n",
      " tensor([0.2028, 0.6609, 0.1815, 0.0594, 0.0141, 0.0179, 0.0106, 0.0045, 0.0044,\n",
      "        0.0048, 0.0032, 0.0018, 0.0009, 0.0011, 0.0011, 0.0017, 0.0023, 0.0031,\n",
      "        0.0020, 0.0021, 0.0032, 0.0039, 0.0032, 0.0020, 0.0020, 0.0015, 0.0028,\n",
      "        0.0033, 0.0011, 0.0020, 0.0019, 0.0022, 0.0025, 0.0009, 0.0008, 0.0016])\n",
      "ens_AM4std_sw_cs_LiH4W256Relu_EY Finished: run 2!\n",
      "All runs finished. Increase <run_num> if you need to continue to train the model.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn  \n",
    "import time \n",
    "import os  \n",
    "\n",
    "######################################################\n",
    "# common functions to split the training and test data\n",
    "# \n",
    "from NNRTMC_utils import NNRTMC_NN_sw, split_train_test_sample, \\\n",
    "draw_batches, data_std_normalization_sw, print_key_results, return_exp_dir\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "######################################################\n",
    "def custom_trainning(NNRTMC_solver, lr, loss, epochs, batch_size, de_save,\n",
    "                     input_torch, output_torch, rsdt_torch,\n",
    "                     indice_train, indice_test, \n",
    "                     eng_loss_frac, device, rng):\n",
    "    # update lr based on test loss\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        NNRTMC_solver.optimizer, mode='min', factor=0.2, patience=50, threshold=1e-3, \n",
    "        threshold_mode='rel', cooldown=50, min_lr=0, eps=1e-08, verbose=True) \n",
    "    NNRTMC_solver.optimizer.param_groups[0]['lr'] = lr\n",
    "    ######################################################\n",
    "    # set training hyperparameter here\n",
    "    ######################################################\n",
    "    sta_time = time.time()\n",
    "    for t in range(epochs): \n",
    "        batch_indice_train = draw_batches(indice_train, batch_size, rng, device, replace=False)\n",
    "        lossv     = NNRTMC_solver.train(batch_indice_train, input_torch, output_torch, rsdt_torch, eng_loss_frac)\n",
    "        lossvtest = NNRTMC_solver.test_loss(indice_test, input_torch,  output_torch, rsdt_torch)\n",
    "        lr_scheduler.step(lossvtest[0]+lossvtest[1]) # update lr based on test loss\n",
    "        if t % de_save == 0:\n",
    "            used_time = time.time() - sta_time  \n",
    "            print( f\"Epoch {t+1:06d} |Train L: {lossv[0]:8.2e} {lossv[1]:8.2e} | Vali. L: {lossvtest[0]:8.2e} {lossvtest[1]:8.2e}  \"\n",
    "                  +f\"| ~ {used_time:3.0f}s | eta {int(used_time*((epochs-t)/de_save/60)) :3d} min\")\n",
    "            sta_time = time.time()\n",
    "            loss.append([[t+1]+lossv+lossvtest]) # append epochs, loss, test loss\n",
    "            # early stop \n",
    "            if NNRTMC_solver.optimizer.param_groups[0]['lr'] < 1e-7:\n",
    "                print(f\"Meet early stop criteria LR = {NNRTMC_solver.optimizer.param_groups[0]['lr']} < 1e-7\" )\n",
    "                print(\"End training\")\n",
    "                break\n",
    "    \n",
    "######################################################\n",
    "def custom_trainning_ens(NNRTMC_solver, lr, loss, epochs, batch_size, de_save,\n",
    "                         input_torch, output_torch, rsdt_torch,\n",
    "                         indice_train, indice_test, \n",
    "                         eng_loss_frac, device, rng):\n",
    "    for mi in range(len(NNRTMC_solver)): \n",
    "        loss_mi = []\n",
    "        custom_trainning(NNRTMC_solver[mi], lr_sta, loss_mi, epochs, batch_size, de_save,\\\n",
    "                         input_torch, output_torch, rsdt_torch,\\\n",
    "                         ind_train, ind_test, eng_loss_frac, device, rng )\n",
    "        loss.append(loss_mi)\n",
    "        \n",
    "######################################################\n",
    "import xarray as xr \n",
    "from get_data_sw_AM4_std import get_data_sw_AM4\n",
    "import argparse, sys\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    torch.cuda.set_device(0) # select gpu_id, default 0 means the first GPU\n",
    "    device = f'cuda:{torch.cuda.current_device()}'\n",
    "    # set random generator\n",
    "    rng = np.random.default_rng(12345)\n",
    "    torch.manual_seed(12345)\n",
    "    # rng = np.random.default_rng()\n",
    "    \n",
    "    #####################################################\n",
    "    # set exp name and runs \n",
    "    # read sky_cond and eng_loss from terminal command\n",
    "    # parser=argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--sky_cond\", help=\"sky condition: af, csaf\")\n",
    "    # parser.add_argument(\"--eng_loss\", help=\"minimize the energy loss: Y/N\")\n",
    "    # args=parser.parse_args()\n",
    "    # sky_cond = args.sky_cond\n",
    "    # eng_loss = args.eng_loss  \n",
    "    sky_cond = 'cs'\n",
    "    sky_cond = 'all'\n",
    "    eng_loss = 'Y'\n",
    "    \n",
    "    hidden_layer_width = 256\n",
    "    # hidden_layer_width = 32\n",
    "    ensemble_num = 2\n",
    "    \n",
    "    Exp_name = f'ens_AM4std_sw_{sky_cond}_LiH4W{hidden_layer_width}Relu_E{eng_loss}' \n",
    "    work_dir = '/tigress/cw55/work/2022_radi_nn/NN_AM4/work/'\n",
    "    total_run_num  = 2\n",
    "    epochs = 2000\n",
    "    de_save = 200 \n",
    "    \n",
    "    if eng_loss != 'Y':\n",
    "        eng_loss_frac = None\n",
    "    else:\n",
    "        if sky_cond == 'cs':\n",
    "            eng_loss_frac = 1e-4 # lower loss weight for cs?\n",
    "        else:\n",
    "            eng_loss_frac = 1e-4\n",
    "        \n",
    "    ######################################################\n",
    "    # create dir for first run or load restart file\n",
    "    run_num, exp_dir = return_exp_dir(work_dir, Exp_name)\n",
    "    # copy script to experiment dir for reference\n",
    "    try:\n",
    "        ossyscmd = f'cp {os.path.abspath(__file__)} {exp_dir}/train_script{run_num:02d}.py' \n",
    "        os.system(ossyscmd) \n",
    "    except: \n",
    "        print('copy trainscript failed')\n",
    "    model_state_dict = []\n",
    "    # get restart info\n",
    "    if run_num == 1:  \n",
    "        nor_para = None\n",
    "        for mi in range(ensemble_num):\n",
    "            model_state_dict.append(None)\n",
    "        lr_sta = 1e-3\n",
    "    else:   # load restart file\n",
    "        for mi in range(ensemble_num):\n",
    "            PATH_last =  exp_dir+f'/model{mi}_restart.{run_num-1:02d}.pth'\n",
    "            restart_data = torch.load(PATH_last)  # load exist results and restart training\n",
    "            print(f'restart from: {PATH_last}')\n",
    "            # read training dataset, nor_para, model parameteres\n",
    "            nor_para = restart_data['nor_para']\n",
    "            model_state_dict.append(restart_data['model_state_dict'])\n",
    "        lr_sta = 1e-4\n",
    "\n",
    "    ######################################################\n",
    "    # load data from AM4 runs\n",
    "    filelist = [f'/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/'+\n",
    "            f'HISTORY/20000101.atmos_8xdaily.tile{_}.nc' for _ in range(1,7)] \n",
    "    # input_array_ori, output_array_ori, rsdt_array_ori = \\\n",
    "    # get_data_sw_AM4(filelist, condition=sky_cond, month_sel = None, day_sel = [1,7]) \n",
    "    input_array_ori, output_array_ori, rsdt_array_ori = \\\n",
    "    get_data_sw_AM4(filelist, condition=sky_cond, month_sel = [1, 4, 7, 12], day_sel = [1]) \n",
    "    \n",
    "    hybrid_p_sigma_para = xr.open_dataset('/tigress/cw55/data/NNRTMC_dataset/AM4_pk_bk_202207.nc')\n",
    "    A_k = hybrid_p_sigma_para.ak.values[None,:]\n",
    "    B_k = hybrid_p_sigma_para.bk.values[None,:]\n",
    "    \n",
    "    print(f\"Features| Input: {input_array_ori.shape[1]},  Output: {output_array_ori.shape[1]}\")\n",
    "    nor_para, input_array, output_array, rsdt_array, day_ind = \\\n",
    "    data_std_normalization_sw(input_array_ori, output_array_ori, rsdt_array_ori, nor_para)  \n",
    " \n",
    "\n",
    "    # divide the training and test data here\n",
    "    # this would be different if restart the training process (be careful!)\n",
    "    ind_train, ind_test = split_train_test_sample(output_array.shape[0], test_ratio=0.3, rng=rng) \n",
    "    \n",
    "    ######################################################\n",
    "    # move all data to GPU to accelerate training\n",
    "    input_torch  = torch.tensor(input_array,  dtype=torch.float32).to(device)\n",
    "    output_torch = torch.tensor(output_array, dtype=torch.float32).to(device) \n",
    "    rsdt_torch   = torch.tensor(rsdt_array,   dtype=torch.float32).to(device) \n",
    "    \n",
    "    ######################################################\n",
    "    # initialize model\n",
    "    NNRTMC_solver = []\n",
    "    for mi in range(ensemble_num):\n",
    "        NNRTMC_solver.append(NNRTMC_NN_sw(device, nor_para, A_k, B_k, \n",
    "                             input_array.shape[1], hidden_layer_width, model_state_dict[mi]))\n",
    "    # training \n",
    "    for i in range(run_num, total_run_num+1): \n",
    "        loss = []\n",
    "        batch_size = max(8000, 8000*i**2)\n",
    "        print(f'Train info >> run: {i} lr_sta: {lr_sta:7.1e}, batch size: {batch_size}')\n",
    "        custom_trainning_ens(NNRTMC_solver, lr_sta, loss, epochs, batch_size, de_save,\\\n",
    "                             input_torch, output_torch, rsdt_torch,\\\n",
    "                             ind_train, ind_test, eng_loss_frac, device, rng )\n",
    "        ######################################################\n",
    "        # save model state dict and data normalization info\n",
    "        data_info = filelist\n",
    "        for mi in range(len(NNRTMC_solver)):\n",
    "            loss_array = np.array(loss[mi]).squeeze().T  \n",
    "            PATH =  exp_dir+f'/model{mi}_restart.{i:02d}.pth'\n",
    "            NNRTMC_solver[mi].save_model_restart(PATH, loss_array, data_info, nor_para)\n",
    "            print('OUTPUT is saved at: '+PATH)        \n",
    "            print_key_results(NNRTMC_solver[mi].predict(input_torch[ind_test,:])*rsdt_array[ind_test,None], \n",
    "                              output_array[ind_test,:]*rsdt_array[ind_test,None], \n",
    "                              nor_para)\n",
    "        lr_sta = 1e-4\n",
    "        print(f'{Exp_name} Finished: run {i}!')  \n",
    "        \n",
    "    print('All runs finished. Increase <run_num> if you need to continue to train the model.')\n",
    "\n",
    "    # # move slurm log to work dir\n",
    "    # job_id = int(os.environ[\"SLURM_JOB_ID\"])\n",
    "    # ossyscmd = f'cp slurm-{job_id}.out {exp_dir}/' \n",
    "    # print(ossyscmd)\n",
    "    # os.system(ossyscmd) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "673db8d1-3704-4fe3-90ca-e6b699015f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:24:36.750950Z",
     "iopub.status.busy": "2023-05-18T17:24:36.750558Z",
     "iopub.status.idle": "2023-05-18T17:24:36.756743Z",
     "shell.execute_reply": "2023-05-18T17:24:36.756350Z",
     "shell.execute_reply.started": "2023-05-18T17:24:36.750932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3953be0-a1d8-4c06-b867-eaf0db32db75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:24:36.757232Z",
     "iopub.status.busy": "2023-05-18T17:24:36.757105Z",
     "iopub.status.idle": "2023-05-18T17:24:36.761441Z",
     "shell.execute_reply": "2023-05-18T17:24:36.761046Z",
     "shell.execute_reply.started": "2023-05-18T17:24:36.757219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1,\n",
       "   0.0018174084834754467,\n",
       "   0.2734147310256958,\n",
       "   0.00172807602211833,\n",
       "   0.07748137414455414]],\n",
       " [[201,\n",
       "   0.0019468782702460885,\n",
       "   0.16403160989284515,\n",
       "   0.0012189534027129412,\n",
       "   0.061190467327833176]],\n",
       " [[401,\n",
       "   0.002103309379890561,\n",
       "   0.08172173798084259,\n",
       "   0.0012347899610176682,\n",
       "   0.06094145402312279]],\n",
       " [[601,\n",
       "   0.001081968075595796,\n",
       "   0.08720286190509796,\n",
       "   0.0012306591961532831,\n",
       "   0.05972469225525856]]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f618aeae-1758-49c3-8fd5-1fc929ee3611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:24:36.761915Z",
     "iopub.status.busy": "2023-05-18T17:24:36.761785Z",
     "iopub.status.idle": "2023-05-18T17:24:36.764990Z",
     "shell.execute_reply": "2023-05-18T17:24:36.764574Z",
     "shell.execute_reply.started": "2023-05-18T17:24:36.761902Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127a013e-f579-4876-a1fc-ddc94d780781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:24:36.765912Z",
     "iopub.status.busy": "2023-05-18T17:24:36.765781Z",
     "iopub.status.idle": "2023-05-18T17:24:36.768950Z",
     "shell.execute_reply": "2023-05-18T17:24:36.768533Z",
     "shell.execute_reply.started": "2023-05-18T17:24:36.765899Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tigress/cw55/work/2022_radi_nn/NN_AM4/work/',\n",
       " 'ens_AM4std_sw_cs_LiH4W256Relu_EY')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir,Exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14025229-1dc6-4203-8559-38a33e9a6a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:24:36.769423Z",
     "iopub.status.busy": "2023-05-18T17:24:36.769297Z",
     "iopub.status.idle": "2023-05-18T17:24:36.911245Z",
     "shell.execute_reply": "2023-05-18T17:24:36.910734Z",
     "shell.execute_reply.started": "2023-05-18T17:24:36.769410Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.01.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.02.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.01.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.02.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/NNRTMC_utils.py\n"
     ]
    }
   ],
   "source": [
    "ls /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e94c98-9a22-42c7-850d-e4d752cd823a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:24:36.912019Z",
     "iopub.status.busy": "2023-05-18T17:24:36.911868Z",
     "iopub.status.idle": "2023-05-18T17:24:37.059212Z",
     "shell.execute_reply": "2023-05-18T17:24:37.058622Z",
     "shell.execute_reply.started": "2023-05-18T17:24:36.912003Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm -rf /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba672f57-1163-49ac-ac3b-03877fe263b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch20",
   "language": "python",
   "name": "pytorch20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
