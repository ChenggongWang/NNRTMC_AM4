{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89aaa5b2-0ab5-451f-aa1b-66d6ff4bf444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T02:36:35.121819Z",
     "iopub.status.busy": "2023-05-19T02:36:35.121679Z",
     "iopub.status.idle": "2023-05-19T02:38:55.033193Z",
     "shell.execute_reply": "2023-05-19T02:38:55.032608Z",
     "shell.execute_reply.started": "2023-05-19T02:36:35.121804Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>| EXP: ens_AM4std_lw_cs_LiH4W256Relu_EN \n",
      ">>| Ensemble size 2 | total_run_num: 3 | epochs per run: 200 \n",
      "First run!\n",
      "Create experiment dir at: \n",
      " /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_cs_LiH4W256Relu_EN\n",
      "cp /tigress/cw55/work/2022_radi_nn/NN_AM4/NNRTMC_utils.py /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_cs_LiH4W256Relu_EN/ \n",
      "copy trainscript failed\n",
      "Data files:\n",
      "['/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile1.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile2.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile3.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile4.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile5.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile6.nc']\n",
      "Data selection:\n",
      "    Month: [1, 4] \n",
      "    Day: [1] \n",
      "Reading data... 0 1 2 3 4 5 \n",
      "Read data done. Use time:   2s\n",
      "Features| Input: 101,  Output: 35\n",
      "Total data size: 884736\n",
      "Total data size: 884736\n",
      "Test data ratio: 0.3\n",
      "Train info >> run: 1 lr_sta: 1.0e-03, batch size: 8000\n",
      "Model #0\n",
      "Epoch 00001 |Train L: 1.15e-01 4.70e+02 | Vali. L: 1.4e-01 1.2e+03  | ~   0s | eta   0 min\n",
      "Epoch 00051 |Train L: 8.78e-03 2.46e+01 | Vali. L: 1.9e-02 5.6e+01  | ~   9s | eta   0 min\n",
      "Epoch 00101 |Train L: 6.52e-03 4.99e+01 | Vali. L: 1.2e-02 3.7e+01  | ~   9s | eta   0 min\n",
      "Epoch 00151 |Train L: 4.49e-03 1.11e+01 | Vali. L: 9.2e-03 2.2e+01  | ~   9s | eta   0 min\n",
      "Model #1\n",
      "Epoch 00001 |Train L: 1.12e-01 5.64e+02 | Vali. L: 1.3e-01 6.2e+02  | ~   0s | eta   0 min\n",
      "Epoch 00051 |Train L: 8.85e-03 2.24e+01 | Vali. L: 2.2e-02 5.7e+01  | ~   9s | eta   0 min\n",
      "Epoch 00101 |Train L: 6.33e-03 1.36e+02 | Vali. L: 1.4e-02 3.5e+01  | ~   9s | eta   0 min\n",
      "Epoch 00151 |Train L: 3.76e-03 1.81e+01 | Vali. L: 1.2e-02 4.0e+01  | ~   9s | eta   0 min\n",
      "Model #0 is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_cs_LiH4W256Relu_EN/model0_restart.01.pth\n",
      "Validation: RMSE\n",
      "[ 3.96e+00  4.19e+00  3.33e-01  1.19e-01  5.40e-02  3.95e-02  3.48e-02\n",
      "  2.82e-02  2.73e-02  1.90e-02  2.21e-02  2.16e-02  2.12e-02  3.28e-02\n",
      "  5.39e-02  5.95e-02  6.51e-02  6.05e-02  6.55e-02  6.48e-02  6.60e-02\n",
      "  7.73e-02  6.49e-02  8.74e-02  8.11e-02  9.37e-02  9.91e-02  1.20e-01\n",
      "  8.87e-02  1.50e-01  1.09e-01  1.33e-01  1.43e-01  1.97e-01  4.22e-01]\n",
      "Validation:       MAE\n",
      "[ 3.26e+00  3.58e+00  1.85e-01  6.30e-02  3.67e-02  2.41e-02  2.05e-02\n",
      "  1.80e-02  1.63e-02  1.32e-02  1.64e-02  1.75e-02  1.71e-02  2.22e-02\n",
      "  4.44e-02  4.57e-02  5.29e-02  4.52e-02  4.66e-02  4.63e-02  5.01e-02\n",
      "  5.92e-02  4.42e-02  6.85e-02  5.87e-02  6.20e-02  7.29e-02  8.42e-02\n",
      "  6.79e-02  1.11e-01  7.84e-02  9.01e-02  8.80e-02  1.27e-01  3.07e-01]\n",
      "Validation:            Bias\n",
      "[-2.13e+00 -3.11e+00  1.18e-01  1.97e-02 -1.93e-02 -1.04e-03 -2.48e-03\n",
      "  2.45e-03  3.07e-03 -6.91e-04 -1.72e-03 -1.10e-02 -6.95e-03  2.07e-02\n",
      "  4.06e-02  2.46e-02  1.86e-02  3.44e-02  1.61e-02 -2.47e-02  2.63e-02\n",
      " -1.35e-02 -4.92e-04  4.59e-02  3.65e-02  4.65e-02  5.76e-03  6.89e-02\n",
      " -3.01e-02  7.39e-02  8.45e-03 -1.14e-02 -2.50e-02  4.58e-02  6.35e-02]\n",
      "Model #1 is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_cs_LiH4W256Relu_EN/model1_restart.01.pth\n",
      "Validation: RMSE\n",
      "[ 3.38e+00  2.08e+00  2.92e-01  1.16e-01  6.53e-02  3.39e-02  3.73e-02\n",
      "  3.68e-02  3.67e-02  3.31e-02  3.49e-02  2.76e-02  2.26e-02  2.61e-02\n",
      "  3.64e-02  5.40e-02  7.73e-02  6.45e-02  6.94e-02  8.27e-02  9.36e-02\n",
      "  8.22e-02  8.16e-02  8.67e-02  1.05e-01  9.94e-02  1.10e-01  1.23e-01\n",
      "  1.06e-01  1.00e-01  9.32e-02  1.35e-01  1.88e-01  3.40e-01  4.90e-01]\n",
      "Validation:       MAE\n",
      "[ 2.30e+00  1.47e+00  1.12e-01  5.20e-02  3.90e-02  2.30e-02  2.24e-02\n",
      "  2.17e-02  1.86e-02  1.98e-02  1.92e-02  1.82e-02  1.50e-02  1.75e-02\n",
      "  2.29e-02  3.76e-02  5.08e-02  4.47e-02  4.97e-02  6.41e-02  7.18e-02\n",
      "  5.87e-02  5.29e-02  6.77e-02  7.84e-02  6.52e-02  6.31e-02  7.59e-02\n",
      "  7.60e-02  6.69e-02  5.73e-02  8.91e-02  1.46e-01  2.67e-01  3.95e-01]\n",
      "Validation:            Bias\n",
      "[-2.14e-01 -6.00e-01  5.68e-02  1.96e-02 -4.63e-03 -9.46e-03  1.42e-02\n",
      "  2.65e-03  1.17e-02  1.43e-02  6.59e-03  1.28e-02  4.96e-03  1.30e-02\n",
      "  8.11e-03 -2.66e-02 -2.40e-02  1.66e-02 -2.70e-02 -1.59e-02 -7.62e-03\n",
      " -1.48e-02 -4.05e-03  1.06e-02  6.59e-02 -6.44e-03 -4.41e-03  5.81e-03\n",
      "  6.30e-02  1.26e-02  1.56e-02 -6.91e-03  4.00e-02  7.01e-02  2.24e-01]\n",
      "ens_AM4std_lw_cs_LiH4W256Relu_EN Finished: run 1!\n",
      "Train info >> run: 2 lr_sta: 1.0e-04, batch size: 32000\n",
      "Model #0\n",
      "Epoch 00001 |Train L: 1.61e-03 8.79e+00 | Vali. L: 4.0e-03 1.6e+01  | ~   0s | eta   0 min\n",
      "Epoch 00051 |Train L: 1.30e-03 6.25e+00 | Vali. L: 3.4e-03 1.1e+01  | ~   4s | eta   0 min\n",
      "Epoch 00101 |Train L: 1.26e-03 4.79e+00 | Vali. L: 3.4e-03 1.1e+01  | ~   4s | eta   0 min\n",
      "Epoch 00151 |Train L: 1.31e-03 5.69e+00 | Vali. L: 3.4e-03 1.1e+01  | ~   4s | eta   0 min\n",
      "Model #1\n",
      "Epoch 00001 |Train L: 1.57e-03 7.72e+00 | Vali. L: 6.0e-03 2.1e+01  | ~   0s | eta   0 min\n",
      "Epoch 00051 |Train L: 1.30e-03 5.79e+00 | Vali. L: 5.8e-03 1.7e+01  | ~   4s | eta   0 min\n",
      "Epoch 00101 |Train L: 1.25e-03 5.56e+00 | Vali. L: 5.8e-03 1.5e+01  | ~   4s | eta   0 min\n",
      "Epoch 00151 |Train L: 1.18e-03 5.03e+00 | Vali. L: 6.0e-03 1.6e+01  | ~   4s | eta   0 min\n",
      "Epoch 00190: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Model #0 is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_cs_LiH4W256Relu_EN/model0_restart.02.pth\n",
      "Validation: RMSE\n",
      "[ 2.50e+00  2.34e+00  2.35e-01  9.95e-02  4.94e-02  3.90e-02  3.03e-02\n",
      "  2.35e-02  2.16e-02  1.67e-02  1.46e-02  1.40e-02  1.11e-02  2.02e-02\n",
      "  2.52e-02  3.84e-02  3.87e-02  4.08e-02  3.98e-02  5.21e-02  4.64e-02\n",
      "  4.99e-02  4.53e-02  5.31e-02  5.70e-02  5.59e-02  5.66e-02  5.47e-02\n",
      "  4.94e-02  5.58e-02  6.39e-02  7.04e-02  9.21e-02  1.36e-01  2.12e-01]\n",
      "Validation:       MAE\n",
      "[ 1.65e+00  1.36e+00  9.23e-02  4.28e-02  2.63e-02  2.05e-02  1.39e-02\n",
      "  1.28e-02  1.15e-02  1.08e-02  9.26e-03  8.33e-03  6.68e-03  1.11e-02\n",
      "  1.70e-02  2.75e-02  2.61e-02  2.78e-02  2.81e-02  3.43e-02  3.24e-02\n",
      "  3.35e-02  3.10e-02  3.61e-02  3.60e-02  3.98e-02  3.88e-02  3.67e-02\n",
      "  3.00e-02  3.26e-02  3.76e-02  3.85e-02  5.09e-02  8.42e-02  1.23e-01]\n",
      "Validation:            Bias\n",
      "[ 5.36e-01 -4.05e-01  4.03e-02  1.69e-02  7.73e-03  3.21e-03  2.44e-03\n",
      "  4.21e-03  2.83e-03  5.73e-03  1.98e-03  1.75e-03  4.20e-03  4.67e-03\n",
      "  5.57e-03 -1.69e-02 -1.32e-03  1.08e-03  5.87e-03  1.42e-02  9.24e-03\n",
      "  8.47e-03 -1.10e-03 -9.14e-03  8.00e-03  3.75e-03  2.53e-02 -4.39e-03\n",
      " -1.01e-03  7.48e-03  1.26e-02  1.26e-02  1.44e-04  2.13e-02  3.80e-02]\n",
      "Model #1 is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_cs_LiH4W256Relu_EN/model1_restart.02.pth\n",
      "Validation: RMSE\n",
      "[ 3.22e+00  1.52e+00  2.49e-01  1.01e-01  6.91e-02  2.98e-02  3.47e-02\n",
      "  3.15e-02  3.27e-02  2.75e-02  2.97e-02  1.58e-02  2.18e-02  2.41e-02\n",
      "  3.84e-02  4.79e-02  5.48e-02  5.91e-02  4.89e-02  4.59e-02  4.54e-02\n",
      "  5.83e-02  7.22e-02  5.04e-02  5.46e-02  8.98e-02  1.15e-01  1.15e-01\n",
      "  7.90e-02  7.91e-02  7.30e-02  8.01e-02  1.01e-01  1.68e-01  2.29e-01]\n",
      "Validation:       MAE\n",
      "[ 1.88e+00  9.93e-01  7.67e-02  3.80e-02  2.79e-02  1.48e-02  1.44e-02\n",
      "  1.30e-02  1.39e-02  1.28e-02  1.39e-02  8.40e-03  9.54e-03  1.11e-02\n",
      "  1.99e-02  2.65e-02  2.84e-02  3.19e-02  2.90e-02  2.92e-02  2.92e-02\n",
      "  3.35e-02  3.70e-02  3.10e-02  3.15e-02  3.56e-02  4.11e-02  4.00e-02\n",
      "  3.62e-02  3.73e-02  3.50e-02  3.60e-02  4.69e-02  7.56e-02  1.13e-01]\n",
      "Validation:            Bias\n",
      "[ 7.78e-01 -1.25e-01  3.67e-02  1.91e-02  1.77e-02  8.28e-04  5.29e-03\n",
      "  4.66e-03  7.44e-03  7.61e-03  9.35e-03  3.17e-03  5.52e-03  3.93e-03\n",
      "  3.64e-03 -9.42e-03 -5.27e-03  1.13e-02  7.84e-03  3.61e-03  7.48e-04\n",
      "  4.01e-03 -9.49e-03 -4.52e-03  2.08e-03  3.83e-03  1.14e-02  1.57e-02\n",
      "  8.37e-03  8.06e-03  3.69e-03 -1.99e-03  1.06e-02  1.90e-02  1.72e-02]\n",
      "ens_AM4std_lw_cs_LiH4W256Relu_EN Finished: run 2!\n",
      "Train info >> run: 3 lr_sta: 1.0e-04, batch size: 72000\n",
      "Model #0\n",
      "Epoch 00001 |Train L: 1.12e-03 4.63e+00 | Vali. L: 3.2e-03 1.1e+01  | ~   0s | eta   0 min\n",
      "Epoch 00051 |Train L: 1.05e-03 4.33e+00 | Vali. L: 3.2e-03 1.0e+01  | ~   4s | eta   0 min\n",
      "Epoch 00071: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Epoch 00101 |Train L: 9.92e-04 4.90e+00 | Vali. L: 3.0e-03 9.3e+00  | ~   4s | eta   0 min\n",
      "Epoch 00151 |Train L: 9.50e-04 3.89e+00 | Vali. L: 2.9e-03 9.2e+00  | ~   4s | eta   0 min\n",
      "Model #1\n",
      "Epoch 00001 |Train L: 1.04e-03 4.30e+00 | Vali. L: 5.9e-03 1.5e+01  | ~   0s | eta   0 min\n",
      "Epoch 00051 |Train L: 1.00e-03 4.33e+00 | Vali. L: 5.9e-03 1.4e+01  | ~   4s | eta   0 min\n",
      "Epoch 00101 |Train L: 9.65e-04 4.11e+00 | Vali. L: 5.9e-03 1.6e+01  | ~   4s | eta   0 min\n",
      "Epoch 00151 |Train L: 1.02e-03 3.93e+00 | Vali. L: 5.8e-03 1.4e+01  | ~   4s | eta   0 min\n",
      "Epoch 00182: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Model #0 is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_cs_LiH4W256Relu_EN/model0_restart.03.pth\n",
      "Validation: RMSE\n",
      "[ 2.44e+00  2.33e+00  2.37e-01  1.00e-01  4.80e-02  3.78e-02  3.07e-02\n",
      "  2.35e-02  2.14e-02  1.55e-02  1.42e-02  1.35e-02  1.01e-02  2.01e-02\n",
      "  2.38e-02  3.49e-02  3.67e-02  3.89e-02  3.86e-02  4.87e-02  4.49e-02\n",
      "  4.62e-02  4.36e-02  4.94e-02  5.38e-02  4.90e-02  4.81e-02  4.84e-02\n",
      "  4.79e-02  5.40e-02  5.89e-02  6.74e-02  8.94e-02  1.22e-01  1.94e-01]\n",
      "Validation:       MAE\n",
      "[ 1.53e+00  1.29e+00  8.45e-02  4.04e-02  2.14e-02  1.71e-02  1.33e-02\n",
      "  1.16e-02  1.08e-02  9.09e-03  8.81e-03  7.68e-03  5.62e-03  1.02e-02\n",
      "  1.55e-02  2.33e-02  2.39e-02  2.54e-02  2.55e-02  3.09e-02  2.93e-02\n",
      "  2.95e-02  2.85e-02  3.16e-02  3.20e-02  3.03e-02  2.93e-02  2.91e-02\n",
      "  2.89e-02  3.01e-02  3.11e-02  3.41e-02  4.51e-02  6.43e-02  9.58e-02]\n",
      "Validation:            Bias\n",
      "[ 3.53e-01 -5.03e-01  4.89e-02  2.41e-02  7.66e-03  7.24e-03  3.82e-03\n",
      "  2.93e-03  2.95e-03  7.39e-04  3.70e-04 -3.38e-04  1.37e-03  3.32e-03\n",
      "  1.13e-03 -5.75e-03 -9.48e-04  3.04e-03 -5.15e-04  6.06e-03  4.39e-03\n",
      " -3.72e-03 -2.90e-03  4.11e-03  5.93e-03  5.75e-04  4.31e-03  1.71e-03\n",
      " -1.80e-03 -3.83e-03 -2.57e-04 -3.09e-04 -1.32e-02 -3.50e-03 -1.53e-03]\n",
      "Model #1 is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_cs_LiH4W256Relu_EN/model1_restart.03.pth\n",
      "Validation: RMSE\n",
      "[ 3.27e+00  1.49e+00  2.44e-01  9.81e-02  7.14e-02  3.06e-02  3.74e-02\n",
      "  3.32e-02  3.40e-02  2.78e-02  2.91e-02  1.59e-02  2.20e-02  2.45e-02\n",
      "  3.84e-02  4.95e-02  5.81e-02  5.58e-02  4.92e-02  4.65e-02  4.46e-02\n",
      "  5.46e-02  7.27e-02  5.05e-02  5.13e-02  9.19e-02  1.16e-01  1.11e-01\n",
      "  7.76e-02  7.56e-02  7.14e-02  8.01e-02  1.01e-01  1.74e-01  2.23e-01]\n",
      "Validation:       MAE\n",
      "[ 1.89e+00  9.78e-01  7.60e-02  3.74e-02  2.80e-02  1.52e-02  1.49e-02\n",
      "  1.34e-02  1.40e-02  1.25e-02  1.33e-02  8.37e-03  9.37e-03  1.10e-02\n",
      "  1.98e-02  2.67e-02  2.89e-02  3.06e-02  2.81e-02  2.89e-02  2.84e-02\n",
      "  3.18e-02  3.59e-02  3.04e-02  2.98e-02  3.57e-02  4.01e-02  3.87e-02\n",
      "  3.56e-02  3.55e-02  3.40e-02  3.52e-02  4.51e-02  7.43e-02  1.08e-01]\n",
      "Validation:            Bias\n",
      "[ 6.94e-01 -2.26e-01  4.48e-02  2.22e-02  1.88e-02  2.51e-03  6.57e-03\n",
      "  5.80e-03  7.68e-03  6.88e-03  7.39e-03  2.01e-03  5.50e-03  5.39e-03\n",
      "  3.53e-03 -1.01e-02 -9.76e-03  1.07e-02  5.38e-03  6.73e-03  4.06e-03\n",
      "  7.34e-03 -7.59e-03 -3.32e-03  2.73e-03  1.00e-02  1.68e-02  1.50e-02\n",
      "  1.16e-02  8.48e-03  7.64e-03  4.38e-04  1.18e-02  1.61e-02  1.48e-02]\n",
      "ens_AM4std_lw_cs_LiH4W256Relu_EN Finished: run 3!\n",
      "All runs finished. Increase <run_num> if you need to continue to train the model.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn  \n",
    "import time \n",
    "import os  \n",
    "\n",
    "######################################################\n",
    "# common functions to split the training and test data\n",
    "# \n",
    "from NNRTMC_utils import NNRTMC_NN_lw, split_train_test_sample, \\\n",
    "draw_batches, data_std_normalization_lw, print_key_results_lw, return_exp_dir\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "######################################################\n",
    "def custom_trainning(NNRTMC_solver, lr, loss, epochs, batch_size, de_save,\n",
    "                     input_torch, output_torch,\n",
    "                     indice_train, indice_test, \n",
    "                     eng_loss_frac, device, rng):\n",
    "    # update lr based on test loss\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        NNRTMC_solver.optimizer, mode='min', factor=0.2, patience=50, threshold=1e-3, \n",
    "        threshold_mode='rel', cooldown=50, min_lr=0, eps=1e-08, verbose=True) \n",
    "    NNRTMC_solver.optimizer.param_groups[0]['lr'] = lr\n",
    "    ######################################################\n",
    "    # set training hyperparameter here\n",
    "    ######################################################\n",
    "    sta_time = time.time()\n",
    "    for t in range(epochs): \n",
    "        batch_indice_train = draw_batches(indice_train, batch_size, rng, device, replace=False)\n",
    "        lossv     = NNRTMC_solver.train(batch_indice_train, input_torch, output_torch, eng_loss_frac)\n",
    "        lossvtest = NNRTMC_solver.test_loss(indice_test, input_torch,  output_torch)\n",
    "        lr_scheduler.step(lossvtest[0]+lossvtest[1]) # update lr based on test loss\n",
    "        if t % de_save == 0:\n",
    "            used_time = time.time() - sta_time  \n",
    "            print( f\"Epoch {t+1:05d} |Train L: {lossv[0]:8.2e} {lossv[1]:8.2e} | Vali. L: {lossvtest[0]:7.1e} {lossvtest[1]:7.1e}  \"\n",
    "                  +f\"| ~ {used_time:3.0f}s | eta {int(used_time*((epochs-t)/de_save/60)) :3d} min\")\n",
    "            sta_time = time.time()\n",
    "            loss.append([[t+1]+lossv+lossvtest]) # append epochs, loss, test loss\n",
    "            # early stop \n",
    "            if NNRTMC_solver.optimizer.param_groups[0]['lr'] < 1e-7:\n",
    "                print(f\"Meet early stop criteria LR = {NNRTMC_solver.optimizer.param_groups[0]['lr']} < 1e-7\" )\n",
    "                print(\"End training\")\n",
    "                break\n",
    "    \n",
    "######################################################\n",
    "def custom_trainning_ens(NNRTMC_solver, lr, loss, epochs, batch_size, de_save,\n",
    "                         input_torch, output_torch,\n",
    "                         indice_train, indice_test, \n",
    "                         eng_loss_frac, device, rng):\n",
    "    for mi in range(len(NNRTMC_solver)): \n",
    "        print(f\"Model #{mi}\")\n",
    "        loss_mi = []\n",
    "        custom_trainning(NNRTMC_solver[mi], lr_sta, loss_mi, epochs, batch_size, de_save,\\\n",
    "                         input_torch, output_torch, \\\n",
    "                         ind_train, ind_test, eng_loss_frac, device, rng )\n",
    "        loss.append(loss_mi)\n",
    "        \n",
    "######################################################\n",
    "import xarray as xr  \n",
    "from get_data_lw_AM4_std import get_data_lw_AM4\n",
    "import argparse, sys\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    torch.cuda.set_device(0) # select gpu_id, default 0 means the first GPU\n",
    "    device = f'cuda:{torch.cuda.current_device()}'\n",
    "    # set random generator\n",
    "    rng = np.random.default_rng(12345)\n",
    "    torch.manual_seed(12345)\n",
    "    # rng = np.random.default_rng()\n",
    "    \n",
    "    #####################################################\n",
    "    # set exp name and runs \n",
    "    # read sky_cond and eng_loss from terminal command\n",
    "    # parser=argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--sky_cond\", help=\"sky condition: af, csaf\")\n",
    "    # parser.add_argument(\"--eng_loss\", help=\"minimize the energy loss: Y/N\")\n",
    "    # parser.add_argument(\"--ensemble_size\", help=\"ensemble_size of NN models\")\n",
    "    # args=parser.parse_args()\n",
    "    # sky_cond = args.sky_cond\n",
    "    # eng_loss = args.eng_loss \n",
    "    # ensemble_num = int(args.ensemble_size) \n",
    "    \n",
    "    sky_cond = 'cs'\n",
    "    eng_loss = 'N' \n",
    "    ensemble_num = 2\n",
    "    \n",
    "    total_run_num  = 3\n",
    "    hidden_layer_width = 256 \n",
    "    \n",
    "    Exp_name = f'ens_AM4std_lw_{sky_cond}_LiH4W{hidden_layer_width}Relu_E{eng_loss}' \n",
    "    work_dir = '/tigress/cw55/work/2022_radi_nn/NN_AM4/work/'\n",
    "    epochs = 200\n",
    "    de_save = 50 \n",
    "    print(f'>>| EXP: {Exp_name} ')\n",
    "    print(f'>>| Ensemble size {ensemble_num} | total_run_num: {total_run_num} | epochs per run: {epochs} ')\n",
    "    \n",
    "    if eng_loss != 'Y':\n",
    "        eng_loss_frac = None\n",
    "    else:\n",
    "        if sky_cond == 'cs':\n",
    "            eng_loss_frac = 1e-4 # lower loss weight for cs?\n",
    "        else:\n",
    "            eng_loss_frac = 1e-4\n",
    "        \n",
    "    ######################################################\n",
    "    # create dir for first run or load restart file\n",
    "    run_num, exp_dir = return_exp_dir(work_dir, Exp_name)\n",
    "    # copy script to experiment dir for reference\n",
    "    try:\n",
    "        ossyscmd = f'cp {os.path.abspath(__file__)} {exp_dir}/train_script{run_num:02d}.py' \n",
    "        os.system(ossyscmd) \n",
    "    except: \n",
    "        print('copy trainscript failed')\n",
    "    model_state_dict = []\n",
    "    # get restart info\n",
    "    if run_num == 1:  \n",
    "        nor_para = None\n",
    "        for mi in range(ensemble_num):\n",
    "            model_state_dict.append(None)\n",
    "        lr_sta = 1e-3\n",
    "    else:   # load restart file\n",
    "        for mi in range(ensemble_num):\n",
    "            PATH_last =  exp_dir+f'/model{mi}_restart.{run_num-1:02d}.pth'\n",
    "            restart_data = torch.load(PATH_last)  # load exist results and restart training\n",
    "            print(f'restart from: {PATH_last}')\n",
    "            # read training dataset, nor_para, model parameteres\n",
    "            nor_para = restart_data['nor_para']\n",
    "            model_state_dict.append(restart_data['model_state_dict'])\n",
    "        lr_sta = 1e-4\n",
    "\n",
    "    ######################################################\n",
    "    # load data from AM4 runs\n",
    "    filelist = [f'/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/'+\n",
    "            f'HISTORY/20000101.atmos_8xdaily.tile{_}.nc' for _ in range(1,7)] \n",
    "    input_array_ori, output_array_ori = \\\n",
    "    get_data_lw_AM4(filelist, condition=sky_cond, month_sel = [1,4], day_sel = [1])   \n",
    "    \n",
    "    hybrid_p_sigma_para = xr.open_dataset('/tigress/cw55/data/NNRTMC_dataset/AM4_pk_bk_202207.nc')\n",
    "    A_k = hybrid_p_sigma_para.ak.values[None,:]\n",
    "    B_k = hybrid_p_sigma_para.bk.values[None,:]\n",
    "    \n",
    "    print(f\"Features| Input: {input_array_ori.shape[1]},  Output: {output_array_ori.shape[1]}\")\n",
    "    nor_para, input_array, output_array = \\\n",
    "    data_std_normalization_lw(input_array_ori, output_array_ori, nor_para)  \n",
    " \n",
    "\n",
    "    # divide the training and test data here\n",
    "    # this would be different if restart the training process (be careful!)\n",
    "    ind_train, ind_test = split_train_test_sample(output_array.shape[0], test_ratio=0.3, rng=rng) \n",
    "    \n",
    "    ######################################################\n",
    "    # move all data to GPU to accelerate training\n",
    "    input_torch  = torch.tensor(input_array,  dtype=torch.float32).to(device)\n",
    "    output_torch = torch.tensor(output_array, dtype=torch.float32).to(device) \n",
    "    \n",
    "    ######################################################\n",
    "    # initialize model\n",
    "    NNRTMC_solver = []\n",
    "    for mi in range(ensemble_num):\n",
    "        NNRTMC_solver.append(NNRTMC_NN_lw(device, nor_para, A_k, B_k, \n",
    "                             input_array.shape[1],output_array.shape[1],\n",
    "                             hidden_layer_width, model_state_dict[mi]))\n",
    "    # training \n",
    "    for i in range(run_num, total_run_num+1): \n",
    "        loss = []\n",
    "        batch_size = max(8000, 8000*i**2)\n",
    "        print(f'Train info >> run: {i} lr_sta: {lr_sta:7.1e}, batch size: {batch_size}')\n",
    "        custom_trainning_ens(NNRTMC_solver, lr_sta, loss, epochs, batch_size, de_save,\\\n",
    "                             input_torch, output_torch, \\\n",
    "                             ind_train, ind_test, eng_loss_frac, device, rng )\n",
    "        ######################################################\n",
    "        # save model state dict and data normalization info\n",
    "        data_info = filelist\n",
    "        for mi in range(len(NNRTMC_solver)):\n",
    "            loss_array = np.array(loss[mi]).squeeze().T  \n",
    "            PATH =  exp_dir+f'/model{mi}_restart.{i:02d}.pth'\n",
    "            NNRTMC_solver[mi].save_model_restart(PATH, loss_array, data_info, nor_para)\n",
    "            print(f'Model #{mi} is saved at: '+PATH)        \n",
    "            print_key_results_lw(NNRTMC_solver[mi].predict(input_torch[ind_test,:]), \n",
    "                                output_array[ind_test,:], \n",
    "                                nor_para)\n",
    "        lr_sta = 1e-4\n",
    "        print(f'{Exp_name} Finished: run {i}!')  \n",
    "        \n",
    "    print('All runs finished. Increase <run_num> if you need to continue to train the model.')\n",
    "\n",
    "    # # move slurm log to work dir\n",
    "    # job_id = int(os.environ[\"SLURM_JOB_ID\"])\n",
    "    # ossyscmd = f'cp slurm-{job_id}.out {exp_dir}/' \n",
    "    # print(ossyscmd)\n",
    "    # os.system(ossyscmd) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408da85a-4a24-4bcd-a515-13203db16536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T02:38:55.034908Z",
     "iopub.status.busy": "2023-05-19T02:38:55.034459Z",
     "iopub.status.idle": "2023-05-19T02:38:55.040327Z",
     "shell.execute_reply": "2023-05-19T02:38:55.039985Z",
     "shell.execute_reply.started": "2023-05-19T02:38:55.034890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0805ba5-e247-4a60-b3ea-db8eaec21616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T02:38:55.041014Z",
     "iopub.status.busy": "2023-05-19T02:38:55.040799Z",
     "iopub.status.idle": "2023-05-19T02:38:55.043589Z",
     "shell.execute_reply": "2023-05-19T02:38:55.043260Z",
     "shell.execute_reply.started": "2023-05-19T02:38:55.041000Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([884736, 35])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673db8d1-3704-4fe3-90ca-e6b699015f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T02:38:55.045554Z",
     "iopub.status.busy": "2023-05-19T02:38:55.045263Z",
     "iopub.status.idle": "2023-05-19T02:38:55.047973Z",
     "shell.execute_reply": "2023-05-19T02:38:55.047633Z",
     "shell.execute_reply.started": "2023-05-19T02:38:55.045541Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3953be0-a1d8-4c06-b867-eaf0db32db75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T02:38:55.049317Z",
     "iopub.status.busy": "2023-05-19T02:38:55.048996Z",
     "iopub.status.idle": "2023-05-19T02:38:55.052031Z",
     "shell.execute_reply": "2023-05-19T02:38:55.051679Z",
     "shell.execute_reply.started": "2023-05-19T02:38:55.049303Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1,\n",
       "   0.0010422501945868134,\n",
       "   4.295931816101074,\n",
       "   0.005909949541091919,\n",
       "   15.041193008422852]],\n",
       " [[51,\n",
       "   0.000999802490696311,\n",
       "   4.334731578826904,\n",
       "   0.005891659762710333,\n",
       "   13.690336227416992]],\n",
       " [[101,\n",
       "   0.0009652427979744971,\n",
       "   4.113218784332275,\n",
       "   0.005891876295208931,\n",
       "   16.248268127441406]],\n",
       " [[151,\n",
       "   0.00102391152177006,\n",
       "   3.9319398403167725,\n",
       "   0.00581090385094285,\n",
       "   14.148933410644531]]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f618aeae-1758-49c3-8fd5-1fc929ee3611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T02:38:55.052849Z",
     "iopub.status.busy": "2023-05-19T02:38:55.052526Z",
     "iopub.status.idle": "2023-05-19T02:38:55.055314Z",
     "shell.execute_reply": "2023-05-19T02:38:55.054983Z",
     "shell.execute_reply.started": "2023-05-19T02:38:55.052832Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "127a013e-f579-4876-a1fc-ddc94d780781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T02:38:55.056115Z",
     "iopub.status.busy": "2023-05-19T02:38:55.055787Z",
     "iopub.status.idle": "2023-05-19T02:38:55.058684Z",
     "shell.execute_reply": "2023-05-19T02:38:55.058316Z",
     "shell.execute_reply.started": "2023-05-19T02:38:55.056099Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tigress/cw55/work/2022_radi_nn/NN_AM4/work/',\n",
       " 'ens_AM4std_lw_cs_LiH4W256Relu_EN')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir,Exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14025229-1dc6-4203-8559-38a33e9a6a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T02:38:55.059447Z",
     "iopub.status.busy": "2023-05-19T02:38:55.059154Z",
     "iopub.status.idle": "2023-05-19T02:38:55.206462Z",
     "shell.execute_reply": "2023-05-19T02:38:55.205945Z",
     "shell.execute_reply.started": "2023-05-19T02:38:55.059434Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model0_restart.01.pth  model1_restart.01.pth  NNRTMC_utils.py\n",
      "model0_restart.02.pth  model1_restart.02.pth\n",
      "model0_restart.03.pth  model1_restart.03.pth\n"
     ]
    }
   ],
   "source": [
    "ls /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1336c892-90f0-4357-9777-f668aedf709d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T02:38:55.207432Z",
     "iopub.status.busy": "2023-05-19T02:38:55.207234Z",
     "iopub.status.idle": "2023-05-19T02:38:55.355465Z",
     "shell.execute_reply": "2023-05-19T02:38:55.354850Z",
     "shell.execute_reply.started": "2023-05-19T02:38:55.207415Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm -rf /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_lw_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea2818-260b-40af-add7-df9577c51958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch20",
   "language": "python",
   "name": "pytorch20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
