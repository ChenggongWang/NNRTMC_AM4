{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89aaa5b2-0ab5-451f-aa1b-66d6ff4bf444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:02:01.406555Z",
     "iopub.status.busy": "2023-05-18T17:02:01.406404Z",
     "iopub.status.idle": "2023-05-18T17:03:04.991485Z",
     "shell.execute_reply": "2023-05-18T17:03:04.990888Z",
     "shell.execute_reply.started": "2023-05-18T17:02:01.406536Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First run!\n",
      "Create experiment dir at: \n",
      " /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY\n",
      "cp /tigress/cw55/work/2022_radi_nn/NN_AM4/NNRTMC_utils.py /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/ \n",
      "Data files:\n",
      "['/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile1.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile2.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile3.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile4.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile5.nc', '/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/HISTORY/20000101.atmos_8xdaily.tile6.nc']\n",
      "Data selection:\n",
      "    Month: [1] \n",
      "    Day: [1] \n",
      "Reading data... 0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/get_data_sw_AM4_std.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  rsdt_r = np.where(np.isclose(rsdt,0,rtol=1e-05, atol=1e-1,), 0, 1/rsdt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Features| Input: 106,  Output: 36\n",
      "Total data size: 442368\n",
      "Night time will be removed! (rsdt==0)\n",
      "Total data size (daylight): (237793,)\n",
      "Total data size: 237793\n",
      "Test data ratio: 0.3\n",
      "Train info >> run: 1 lr_sta: 1.0e-03, batch size: 8000\n",
      "Epoch 000001 |Train L: 5.67e-01 8.92e+01 | Vali. L: 6.98e-01 1.13e+02  | ~   0s | eta   0 min\n",
      "Epoch 000191 |Train L: 1.25e-02 1.41e+00 | Vali. L: 2.84e-02 2.69e+00  | ~  11s | eta   0 min\n",
      "Epoch 000001 |Train L: 5.78e-01 1.04e+02 | Vali. L: 6.98e-01 1.12e+02  | ~   0s | eta   0 min\n",
      "Epoch 000191 |Train L: 1.15e-02 7.73e-01 | Vali. L: 3.65e-02 2.90e+00  | ~  10s | eta   0 min\n",
      "Epoch 000001 |Train L: 6.91e-01 2.31e+02 | Vali. L: 7.43e-01 1.19e+02  | ~   0s | eta   0 min\n",
      "Epoch 000191 |Train L: 1.38e-02 9.82e-01 | Vali. L: 4.81e-02 3.41e+00  | ~  10s | eta   0 min\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.01.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([9.5183, 7.0722, 9.9275, 1.8978, 1.3815, 0.7027, 0.4219, 0.2158, 0.1478,\n",
      "        0.1357, 0.1017, 0.0687, 0.0527, 0.0318, 0.0233, 0.0578, 0.0622, 0.0616,\n",
      "        0.0952, 0.0686, 0.1061, 0.1224, 0.0979, 0.0824, 0.1120, 0.0877, 0.0962,\n",
      "        0.0891, 0.0869, 0.0893, 0.1035, 0.1179, 0.0888, 0.0627, 0.0575, 0.0685]) \n",
      " tensor([4.2847, 3.7392, 4.1823, 0.8645, 0.5362, 0.3216, 0.2273, 0.1333, 0.0905,\n",
      "        0.0750, 0.0525, 0.0341, 0.0254, 0.0171, 0.0147, 0.0314, 0.0363, 0.0387,\n",
      "        0.0530, 0.0424, 0.0554, 0.0640, 0.0539, 0.0473, 0.0589, 0.0499, 0.0524,\n",
      "        0.0471, 0.0470, 0.0425, 0.0457, 0.0487, 0.0395, 0.0321, 0.0322, 0.0371]) \n",
      " tensor([-9.1856e-01, -1.5366e+00, -1.5175e+00,  7.3035e-01,  4.5713e-01,\n",
      "         2.5210e-01,  1.8999e-01,  1.0779e-01,  7.0973e-02,  6.7665e-02,\n",
      "         4.7579e-02,  3.0715e-02,  2.2521e-02,  1.2956e-02,  3.5225e-03,\n",
      "         1.3931e-02,  1.5854e-02,  1.4466e-02,  2.3424e-02,  8.1514e-03,\n",
      "        -7.6908e-03, -3.8164e-02, -1.5774e-02, -6.9200e-04,  3.5111e-02,\n",
      "         9.1682e-03, -1.3744e-02, -1.1479e-02,  5.8916e-03, -1.6372e-02,\n",
      "        -1.4334e-02, -1.5283e-02, -5.6870e-03,  6.1476e-03,  1.4297e-02,\n",
      "         1.9930e-02])\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.01.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([12.3639,  8.7172, 14.1776,  1.4322,  0.7342,  0.5357,  0.4366,  0.2801,\n",
      "         0.1437,  0.0995,  0.0604,  0.0322,  0.0253,  0.0192,  0.0255,  0.0474,\n",
      "         0.0592,  0.0880,  0.0812,  0.0763,  0.0786,  0.1032,  0.1068,  0.1300,\n",
      "         0.1148,  0.1331,  0.1109,  0.1467,  0.0858,  0.0800,  0.0717,  0.0629,\n",
      "         0.0674,  0.0749,  0.0766,  0.0826]) \n",
      " tensor([6.0321, 4.8985, 5.6383, 0.8656, 0.4495, 0.3408, 0.2655, 0.1666, 0.0936,\n",
      "        0.0613, 0.0351, 0.0194, 0.0147, 0.0119, 0.0169, 0.0304, 0.0380, 0.0489,\n",
      "        0.0477, 0.0471, 0.0494, 0.0551, 0.0586, 0.0646, 0.0626, 0.0662, 0.0589,\n",
      "        0.0752, 0.0463, 0.0442, 0.0409, 0.0338, 0.0332, 0.0350, 0.0354, 0.0387]) \n",
      " tensor([ 1.6824e-01, -1.3964e+00, -2.3503e+00,  1.5776e-01, -2.7487e-02,\n",
      "        -2.9960e-02,  2.2875e-02,  4.0007e-02, -2.5529e-03,  1.8789e-03,\n",
      "         4.0189e-03, -1.3018e-03,  1.0609e-03,  6.1443e-04, -4.7330e-03,\n",
      "         1.5720e-03, -3.6265e-03,  1.2171e-02,  1.7308e-02, -4.6851e-03,\n",
      "        -6.3625e-03, -9.0741e-03, -2.3939e-02, -2.9624e-02, -2.5737e-02,\n",
      "        -3.8808e-02, -2.7215e-02, -1.7952e-02, -1.0286e-02,  2.3354e-02,\n",
      "         1.3223e-02,  4.0136e-03,  1.3601e-03, -5.8259e-03, -7.5450e-03,\n",
      "        -7.8356e-03])\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model2_restart.01.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([6.7389, 6.4860, 7.7470, 2.1409, 0.8931, 0.5402, 0.3021, 0.1945, 0.1516,\n",
      "        0.1002, 0.0693, 0.0482, 0.0335, 0.0271, 0.0333, 0.0355, 0.0591, 0.0676,\n",
      "        0.0782, 0.0695, 0.0807, 0.0868, 0.1476, 0.1211, 0.1266, 0.0917, 0.1182,\n",
      "        0.1267, 0.0870, 0.0808, 0.1418, 0.1266, 0.1346, 0.1523, 0.1613, 0.1743]) \n",
      " tensor([3.7300, 3.7354, 3.8791, 0.9650, 0.4366, 0.2890, 0.1805, 0.1178, 0.0878,\n",
      "        0.0575, 0.0398, 0.0269, 0.0185, 0.0156, 0.0193, 0.0232, 0.0366, 0.0410,\n",
      "        0.0475, 0.0439, 0.0498, 0.0515, 0.0640, 0.0567, 0.0591, 0.0543, 0.0582,\n",
      "        0.0573, 0.0457, 0.0444, 0.0617, 0.0521, 0.0490, 0.0496, 0.0505, 0.0576]) \n",
      " tensor([ 8.3133e-01, -1.2291e+00,  2.2395e-01,  4.3008e-01,  2.1178e-01,\n",
      "         2.0829e-01,  1.1224e-01,  3.9381e-02,  2.4678e-02, -3.3651e-04,\n",
      "        -4.4036e-03, -3.4474e-03, -2.0130e-03,  1.7534e-03,  7.2919e-03,\n",
      "         8.7645e-03,  1.9503e-02,  7.0966e-03, -2.5613e-03,  2.1678e-03,\n",
      "        -1.6533e-02,  7.9970e-03, -2.2193e-02, -1.1297e-02, -8.7925e-03,\n",
      "         2.2743e-02, -8.3889e-03, -2.1046e-02, -1.4141e-03,  1.3350e-02,\n",
      "         3.2311e-02,  2.8092e-02,  2.9223e-02,  3.2917e-02,  3.4299e-02,\n",
      "         3.8478e-02])\n",
      "ens_AM4std_sw_cs_LiH4W256Relu_EY Finished: run 1!\n",
      "Train info >> run: 2 lr_sta: 1.0e-04, batch size: 32000\n",
      "Epoch 000001 |Train L: 8.91e-03 5.59e-01 | Vali. L: 2.88e-02 2.56e+00  | ~   0s | eta   0 min\n",
      "Epoch 00053: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Epoch 00154: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 000191 |Train L: 8.72e-03 4.50e-01 | Vali. L: 2.87e-02 2.42e+00  | ~   4s | eta   0 min\n",
      "Epoch 000001 |Train L: 8.95e-03 8.90e-01 | Vali. L: 2.49e-02 2.86e+00  | ~   0s | eta   0 min\n",
      "Epoch 000191 |Train L: 6.73e-03 4.48e-01 | Vali. L: 2.47e-02 2.38e+00  | ~   4s | eta   0 min\n",
      "Epoch 000001 |Train L: 1.36e-02 7.45e-01 | Vali. L: 4.38e-02 3.10e+00  | ~   0s | eta   0 min\n",
      "Epoch 00052: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Epoch 00153: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 000191 |Train L: 7.53e-03 5.43e-01 | Vali. L: 4.78e-02 3.89e+00  | ~   4s | eta   0 min\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.02.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([9.7066, 5.9252, 9.7676, 1.8991, 1.3081, 0.5910, 0.2861, 0.1546, 0.1222,\n",
      "        0.0961, 0.0765, 0.0544, 0.0452, 0.0266, 0.0219, 0.0578, 0.0642, 0.0607,\n",
      "        0.0828, 0.0594, 0.1058, 0.1024, 0.0772, 0.0779, 0.1166, 0.0815, 0.1027,\n",
      "        0.1108, 0.0890, 0.0974, 0.1095, 0.1231, 0.0971, 0.0696, 0.0573, 0.0625]) \n",
      " tensor([4.2430, 3.2611, 4.0683, 0.7708, 0.4638, 0.2580, 0.1520, 0.0902, 0.0655,\n",
      "        0.0491, 0.0371, 0.0251, 0.0202, 0.0136, 0.0136, 0.0306, 0.0361, 0.0366,\n",
      "        0.0446, 0.0369, 0.0524, 0.0544, 0.0438, 0.0449, 0.0588, 0.0450, 0.0491,\n",
      "        0.0524, 0.0455, 0.0437, 0.0456, 0.0467, 0.0378, 0.0292, 0.0271, 0.0309]) \n",
      " tensor([-0.7257, -0.9186, -1.4239,  0.4805,  0.2944,  0.1540,  0.0802,  0.0192,\n",
      "         0.0087,  0.0255,  0.0208,  0.0142,  0.0133,  0.0068,  0.0028,  0.0169,\n",
      "         0.0179,  0.0081,  0.0186,  0.0059, -0.0127, -0.0220, -0.0017,  0.0105,\n",
      "         0.0339, -0.0046, -0.0179, -0.0257,  0.0017, -0.0149, -0.0205, -0.0232,\n",
      "        -0.0154, -0.0055,  0.0018,  0.0070])\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.02.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([10.9334,  7.2605, 12.9043,  1.4418,  0.7548,  0.5662,  0.3984,  0.2194,\n",
      "         0.1050,  0.0817,  0.0583,  0.0338,  0.0276,  0.0187,  0.0229,  0.0357,\n",
      "         0.0483,  0.0828,  0.0844,  0.0739,  0.0787,  0.0866,  0.0877,  0.1184,\n",
      "         0.0937,  0.1058,  0.0880,  0.1292,  0.0905,  0.0657,  0.0580,  0.0681,\n",
      "         0.0764,  0.0835,  0.0840,  0.0903]) \n",
      " tensor([4.9416, 3.8539, 4.9777, 0.7747, 0.3894, 0.2951, 0.2060, 0.1198, 0.0648,\n",
      "        0.0464, 0.0317, 0.0188, 0.0143, 0.0114, 0.0141, 0.0222, 0.0297, 0.0436,\n",
      "        0.0460, 0.0430, 0.0457, 0.0461, 0.0465, 0.0580, 0.0509, 0.0523, 0.0470,\n",
      "        0.0590, 0.0451, 0.0366, 0.0326, 0.0321, 0.0322, 0.0337, 0.0340, 0.0381]) \n",
      " tensor([ 0.8957, -1.5258, -1.1151,  0.2648,  0.2257,  0.2002,  0.1323,  0.0617,\n",
      "         0.0182,  0.0189,  0.0151,  0.0060,  0.0064,  0.0021,  0.0041,  0.0084,\n",
      "         0.0068,  0.0197,  0.0201,  0.0042, -0.0095, -0.0032, -0.0055, -0.0085,\n",
      "        -0.0041, -0.0199, -0.0170, -0.0293, -0.0143,  0.0102,  0.0054, -0.0052,\n",
      "        -0.0117, -0.0157, -0.0156, -0.0164])\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model2_restart.02.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([7.1061, 7.2610, 8.4361, 2.2738, 0.8797, 0.5160, 0.3011, 0.2129, 0.1685,\n",
      "        0.1069, 0.0744, 0.0505, 0.0358, 0.0291, 0.0358, 0.0352, 0.0643, 0.0708,\n",
      "        0.0664, 0.0727, 0.0782, 0.0840, 0.1549, 0.1341, 0.1429, 0.0926, 0.1396,\n",
      "        0.1378, 0.0958, 0.0755, 0.1408, 0.1226, 0.1335, 0.1550, 0.1667, 0.1823]) \n",
      " tensor([3.8042, 3.9334, 3.8702, 1.0068, 0.4384, 0.2756, 0.1760, 0.1247, 0.0944,\n",
      "        0.0582, 0.0388, 0.0254, 0.0178, 0.0157, 0.0198, 0.0226, 0.0378, 0.0407,\n",
      "        0.0398, 0.0425, 0.0460, 0.0489, 0.0636, 0.0575, 0.0609, 0.0511, 0.0605,\n",
      "        0.0581, 0.0457, 0.0399, 0.0562, 0.0462, 0.0438, 0.0458, 0.0478, 0.0558]) \n",
      " tensor([ 0.5457, -1.6727, -0.6097,  0.5787,  0.2381,  0.1672,  0.0942,  0.0614,\n",
      "         0.0522,  0.0285,  0.0200,  0.0124,  0.0092,  0.0080,  0.0096,  0.0070,\n",
      "         0.0193,  0.0135, -0.0025,  0.0135, -0.0071,  0.0064, -0.0205, -0.0239,\n",
      "        -0.0262,  0.0095, -0.0208, -0.0242, -0.0090,  0.0098,  0.0336,  0.0254,\n",
      "         0.0263,  0.0317,  0.0344,  0.0401])\n",
      "ens_AM4std_sw_cs_LiH4W256Relu_EY Finished: run 2!\n",
      "Train info >> run: 3 lr_sta: 1.0e-04, batch size: 72000\n",
      "Epoch 000001 |Train L: 7.44e-03 4.36e-01 | Vali. L: 2.98e-02 2.49e+00  | ~   0s | eta   0 min\n",
      "Epoch 000191 |Train L: 6.32e-03 4.06e-01 | Vali. L: 2.86e-02 2.23e+00  | ~   4s | eta   0 min\n",
      "Epoch 000001 |Train L: 7.39e-03 4.73e-01 | Vali. L: 2.45e-02 2.38e+00  | ~   0s | eta   0 min\n",
      "Epoch 00148: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Epoch 000191 |Train L: 6.34e-03 4.42e-01 | Vali. L: 2.32e-02 2.34e+00  | ~   4s | eta   0 min\n",
      "Epoch 000001 |Train L: 7.47e-03 5.32e-01 | Vali. L: 4.73e-02 3.83e+00  | ~   0s | eta   0 min\n",
      "Epoch 00056: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Epoch 00157: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 000191 |Train L: 7.01e-03 5.21e-01 | Vali. L: 4.97e-02 3.94e+00  | ~   4s | eta   0 min\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.03.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([9.9306, 5.9562, 9.9996, 1.9674, 1.2961, 0.5844, 0.2807, 0.1566, 0.1245,\n",
      "        0.0991, 0.0796, 0.0562, 0.0464, 0.0269, 0.0221, 0.0561, 0.0655, 0.0626,\n",
      "        0.0872, 0.0596, 0.1054, 0.1022, 0.0771, 0.0760, 0.1191, 0.0824, 0.1029,\n",
      "        0.1140, 0.0930, 0.0955, 0.1082, 0.1256, 0.1007, 0.0724, 0.0593, 0.0644]) \n",
      " tensor([4.2638, 3.2626, 4.0827, 0.7839, 0.4621, 0.2570, 0.1505, 0.0903, 0.0657,\n",
      "        0.0499, 0.0380, 0.0255, 0.0205, 0.0135, 0.0136, 0.0299, 0.0364, 0.0371,\n",
      "        0.0457, 0.0368, 0.0521, 0.0538, 0.0438, 0.0438, 0.0592, 0.0451, 0.0488,\n",
      "        0.0534, 0.0464, 0.0428, 0.0450, 0.0471, 0.0385, 0.0297, 0.0274, 0.0314]) \n",
      " tensor([-8.0713e-01, -8.5382e-01, -1.5120e+00,  4.8604e-01,  2.9211e-01,\n",
      "         1.5370e-01,  7.6766e-02,  1.4586e-02,  5.3883e-03,  2.3852e-02,\n",
      "         1.9983e-02,  1.3783e-02,  1.3175e-02,  6.4851e-03,  2.0897e-03,\n",
      "         1.5945e-02,  1.7881e-02,  8.5953e-03,  1.8697e-02,  6.5113e-03,\n",
      "        -1.2352e-02, -2.2794e-02, -3.2653e-03,  9.8563e-03,  3.4555e-02,\n",
      "        -5.0137e-03, -1.8327e-02, -2.7684e-02,  1.7250e-03, -1.5026e-02,\n",
      "        -2.0807e-02, -2.4610e-02, -1.7174e-02, -7.2302e-03,  6.0954e-04,\n",
      "         6.2471e-03])\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.03.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([10.9389,  7.1707, 12.9263,  1.4981,  0.7816,  0.5778,  0.4035,  0.2160,\n",
      "         0.1044,  0.0800,  0.0573,  0.0335,  0.0277,  0.0186,  0.0233,  0.0351,\n",
      "         0.0473,  0.0817,  0.0846,  0.0753,  0.0799,  0.0876,  0.0875,  0.1230,\n",
      "         0.0980,  0.1061,  0.0853,  0.1270,  0.0874,  0.0718,  0.0596,  0.0639,\n",
      "         0.0712,  0.0776,  0.0773,  0.0835]) \n",
      " tensor([4.9454, 3.7690, 5.0020, 0.7969, 0.3961, 0.2970, 0.2068, 0.1179, 0.0639,\n",
      "        0.0453, 0.0310, 0.0185, 0.0142, 0.0113, 0.0141, 0.0218, 0.0290, 0.0430,\n",
      "        0.0458, 0.0434, 0.0459, 0.0460, 0.0462, 0.0587, 0.0516, 0.0519, 0.0455,\n",
      "        0.0579, 0.0440, 0.0384, 0.0331, 0.0311, 0.0306, 0.0316, 0.0317, 0.0358]) \n",
      " tensor([ 1.0162, -1.5640, -0.9935,  0.2846,  0.2275,  0.1984,  0.1298,  0.0568,\n",
      "         0.0143,  0.0168,  0.0144,  0.0059,  0.0066,  0.0022,  0.0038,  0.0081,\n",
      "         0.0061,  0.0197,  0.0197,  0.0074, -0.0116, -0.0038, -0.0060, -0.0092,\n",
      "        -0.0084, -0.0216, -0.0159, -0.0295, -0.0122,  0.0148,  0.0098, -0.0018,\n",
      "        -0.0090, -0.0129, -0.0125, -0.0130])\n",
      "OUTPUT is saved at: /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model2_restart.03.pth\n",
      "TEST: RMSE, MAE, Bias\n",
      "tensor([7.0876, 7.2826, 8.3102, 2.2996, 0.8852, 0.5075, 0.2980, 0.2127, 0.1692,\n",
      "        0.1075, 0.0747, 0.0507, 0.0359, 0.0289, 0.0360, 0.0351, 0.0643, 0.0710,\n",
      "        0.0671, 0.0731, 0.0785, 0.0837, 0.1566, 0.1355, 0.1447, 0.0944, 0.1416,\n",
      "        0.1391, 0.0964, 0.0788, 0.1475, 0.1282, 0.1383, 0.1588, 0.1698, 0.1852]) \n",
      " tensor([3.7901, 3.9439, 3.8313, 1.0193, 0.4408, 0.2715, 0.1743, 0.1243, 0.0945,\n",
      "        0.0584, 0.0390, 0.0255, 0.0178, 0.0156, 0.0199, 0.0225, 0.0377, 0.0406,\n",
      "        0.0398, 0.0425, 0.0460, 0.0486, 0.0638, 0.0576, 0.0613, 0.0514, 0.0610,\n",
      "        0.0582, 0.0458, 0.0408, 0.0579, 0.0475, 0.0448, 0.0465, 0.0482, 0.0561]) \n",
      " tensor([ 0.5421, -1.5741, -0.5986,  0.6019,  0.2470,  0.1629,  0.0884,  0.0562,\n",
      "         0.0483,  0.0263,  0.0191,  0.0120,  0.0089,  0.0078,  0.0096,  0.0063,\n",
      "         0.0188,  0.0125, -0.0049,  0.0123, -0.0089,  0.0053, -0.0216, -0.0237,\n",
      "        -0.0279,  0.0091, -0.0214, -0.0242, -0.0088,  0.0116,  0.0356,  0.0269,\n",
      "         0.0274,  0.0325,  0.0351,  0.0408])\n",
      "ens_AM4std_sw_cs_LiH4W256Relu_EY Finished: run 3!\n",
      "All runs finished. Increase <run_num> if you need to continue to train the model.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn  \n",
    "import time \n",
    "import os  \n",
    "\n",
    "######################################################\n",
    "# common functions to split the training and test data\n",
    "# \n",
    "from NNRTMC_utils import NNRTMC_NN_sw, split_train_test_sample, \\\n",
    "draw_batches, data_std_normalization_sw, print_key_results, return_exp_dir\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "######################################################\n",
    "def custom_trainning(NNRTMC_solver, lr, loss, epochs, batch_size, de_save,\n",
    "                     input_torch, output_torch, rsdt_torch,\n",
    "                     indice_train, indice_test, \n",
    "                     eng_loss_frac, device, rng):\n",
    "    # update lr based on test loss\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        NNRTMC_solver.optimizer, mode='min', factor=0.2, patience=50, threshold=1e-3, \n",
    "        threshold_mode='rel', cooldown=50, min_lr=0, eps=1e-08, verbose=True) \n",
    "    NNRTMC_solver.optimizer.param_groups[0]['lr'] = lr\n",
    "    ######################################################\n",
    "    # set training hyperparameter here\n",
    "    ######################################################\n",
    "    sta_time = time.time()\n",
    "    for t in range(epochs): \n",
    "        batch_indice_train = draw_batches(indice_train, batch_size, rng, device, replace=False)\n",
    "        lossv     = NNRTMC_solver.train(batch_indice_train, input_torch, output_torch, rsdt_torch, eng_loss_frac)\n",
    "        lossvtest = NNRTMC_solver.test_loss(indice_test, input_torch,  output_torch, rsdt_torch)\n",
    "        lr_scheduler.step(lossvtest[0]+lossvtest[1]) # update lr based on test loss\n",
    "        if t % de_save == 0:\n",
    "            used_time = time.time() - sta_time  \n",
    "            print( f\"Epoch {t+1:06d} |Train L: {lossv[0]:8.2e} {lossv[1]:8.2e} | Vali. L: {lossvtest[0]:8.2e} {lossvtest[1]:8.2e}  \"\n",
    "                  +f\"| ~ {used_time:3.0f}s | eta {int(used_time*((epochs-t)/de_save/60)) :3d} min\")\n",
    "            sta_time = time.time()\n",
    "            loss.append([[t+1]+lossv+lossvtest]) # append epochs, loss, test loss\n",
    "            # early stop \n",
    "            if NNRTMC_solver.optimizer.param_groups[0]['lr'] < 1e-7:\n",
    "                print(f\"Meet early stop criteria LR = {NNRTMC_solver.optimizer.param_groups[0]['lr']} < 1e-7\" )\n",
    "                print(\"End training\")\n",
    "                break\n",
    "    \n",
    "######################################################\n",
    "def custom_trainning_ens(NNRTMC_solver, lr, loss, epochs, batch_size, de_save,\n",
    "                         input_torch, output_torch, rsdt_torch,\n",
    "                         indice_train, indice_test, \n",
    "                         eng_loss_frac, device, rng):\n",
    "    for mi in range(len(NNRTMC_solver)): \n",
    "        loss_mi = []\n",
    "        custom_trainning(NNRTMC_solver[mi], lr_sta, loss_mi, epochs, batch_size, de_save,\\\n",
    "                         input_torch, output_torch, rsdt_torch,\\\n",
    "                         ind_train, ind_test, eng_loss_frac, device, rng )\n",
    "        loss.append(loss_mi)\n",
    "        \n",
    "######################################################\n",
    "import xarray as xr \n",
    "from get_data_sw_AM4_std import get_data_sw_AM4\n",
    "import argparse, sys\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    torch.cuda.set_device(0) # select gpu_id, default 0 means the first GPU\n",
    "    device = f'cuda:{torch.cuda.current_device()}'\n",
    "    # set random generator\n",
    "    rng = np.random.default_rng(12345)\n",
    "    torch.manual_seed(12345)\n",
    "    # rng = np.random.default_rng()\n",
    "    \n",
    "    #####################################################\n",
    "    # set exp name and runs \n",
    "    # read sky_cond and eng_loss from terminal command\n",
    "    # parser=argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--sky_cond\", help=\"sky condition: af, csaf\")\n",
    "    # parser.add_argument(\"--eng_loss\", help=\"minimize the energy loss: Y/N\")\n",
    "    # args=parser.parse_args()\n",
    "    # sky_cond = args.sky_cond\n",
    "    # eng_loss = args.eng_loss  \n",
    "    sky_cond = 'cs'\n",
    "    eng_loss = 'Y'\n",
    "    \n",
    "    hidden_layer_width = 256\n",
    "    # hidden_layer_width = 32\n",
    "    ensemble_num = 3\n",
    "    \n",
    "    Exp_name = f'ens_AM4std_sw_{sky_cond}_LiH4W{hidden_layer_width}Relu_E{eng_loss}' \n",
    "    work_dir = '/tigress/cw55/work/2022_radi_nn/NN_AM4/work/'\n",
    "    total_run_num  = 3\n",
    "    epochs = 200\n",
    "    de_save = 190 \n",
    "    \n",
    "    if eng_loss != 'Y':\n",
    "        eng_loss_frac = None\n",
    "    else:\n",
    "        if sky_cond == 'cs':\n",
    "            eng_loss_frac = 1e-4 # lower loss weight for cs?\n",
    "        else:\n",
    "            eng_loss_frac = 1e-4\n",
    "        \n",
    "    ######################################################\n",
    "    # create dir for first run or load restart file\n",
    "    run_num, exp_dir = return_exp_dir(work_dir, Exp_name)\n",
    "    # copy script to experiment dir for reference\n",
    "    try:\n",
    "        ossyscmd = f'cp {os.path.abspath(__file__)} {exp_dir}/train_script{run_num:02d}.py' \n",
    "        os.system(ossyscmd) \n",
    "    except: \n",
    "        print('copy trainscript failed')\n",
    "    model_state_dict = []\n",
    "    # get restart info\n",
    "    if run_num == 1:  \n",
    "        nor_para = None\n",
    "        for mi in range(ensemble_num):\n",
    "            model_state_dict.append(None)\n",
    "        lr_sta = 1e-3\n",
    "    else:   # load restart file\n",
    "        for mi in range(ensemble_num):\n",
    "            PATH_last =  exp_dir+f'/model{mi}_restart.{run_num-1:02d}.pth'\n",
    "            restart_data = torch.load(PATH_last)  # load exist results and restart training\n",
    "            print(f'restart from: {PATH_last}')\n",
    "            # read training dataset, nor_para, model parameteres\n",
    "            nor_para = restart_data['nor_para']\n",
    "            model_state_dict.append(restart_data['model_state_dict'])\n",
    "        lr_sta = 1e-4\n",
    "\n",
    "    ######################################################\n",
    "    # load data from AM4 runs\n",
    "    filelist = [f'/scratch/gpfs/cw55/AM4/work/CTL2000_train_y2000_stellarcpu_intelmpi_22_768PE/'+\n",
    "            f'HISTORY/20000101.atmos_8xdaily.tile{_}.nc' for _ in range(1,7)] \n",
    "    # input_array_ori, output_array_ori, rsdt_array_ori = \\\n",
    "    # get_data_sw_AM4(filelist, condition=sky_cond, month_sel = None, day_sel = [1,7]) \n",
    "    input_array_ori, output_array_ori, rsdt_array_ori = \\\n",
    "    get_data_sw_AM4(filelist, condition=sky_cond, month_sel = [1], day_sel = [1]) \n",
    "    \n",
    "    hybrid_p_sigma_para = xr.open_dataset('/tigress/cw55/data/NNRTMC_dataset/AM4_pk_bk_202207.nc')\n",
    "    A_k = hybrid_p_sigma_para.ak.values[None,:]\n",
    "    B_k = hybrid_p_sigma_para.bk.values[None,:]\n",
    "    \n",
    "    print(f\"Features| Input: {input_array_ori.shape[1]},  Output: {output_array_ori.shape[1]}\")\n",
    "    nor_para, input_array, output_array, rsdt_array, day_ind = \\\n",
    "    data_std_normalization_sw(input_array_ori, output_array_ori, rsdt_array_ori, nor_para)  \n",
    " \n",
    "\n",
    "    # divide the training and test data here\n",
    "    # this would be different if restart the training process (be careful!)\n",
    "    ind_train, ind_test = split_train_test_sample(output_array.shape[0], test_ratio=0.3, rng=rng) \n",
    "    \n",
    "    ######################################################\n",
    "    # move all data to GPU to accelerate training\n",
    "    input_torch  = torch.tensor(input_array,  dtype=torch.float32).to(device)\n",
    "    output_torch = torch.tensor(output_array, dtype=torch.float32).to(device) \n",
    "    rsdt_torch   = torch.tensor(rsdt_array,   dtype=torch.float32).to(device) \n",
    "    \n",
    "    ######################################################\n",
    "    # initialize model\n",
    "    NNRTMC_solver = []\n",
    "    for mi in range(ensemble_num):\n",
    "        NNRTMC_solver.append(NNRTMC_NN_sw(device, nor_para, A_k, B_k, \n",
    "                             input_array.shape[1], hidden_layer_width, model_state_dict[mi]))\n",
    "    # training \n",
    "    for i in range(run_num, total_run_num+1): \n",
    "        loss = []\n",
    "        batch_size = max(8000, 8000*i**2)\n",
    "        print(f'Train info >> run: {i} lr_sta: {lr_sta:7.1e}, batch size: {batch_size}')\n",
    "        custom_trainning_ens(NNRTMC_solver, lr_sta, loss, epochs, batch_size, de_save,\\\n",
    "                             input_torch, output_torch, rsdt_torch,\\\n",
    "                             ind_train, ind_test, eng_loss_frac, device, rng )\n",
    "        ######################################################\n",
    "        # save model state dict and data normalization info\n",
    "        data_info = filelist\n",
    "        for mi in range(len(NNRTMC_solver)):\n",
    "            loss_array = np.array(loss[mi]).squeeze().T  \n",
    "            PATH =  exp_dir+f'/model{mi}_restart.{i:02d}.pth'\n",
    "            NNRTMC_solver[mi].save_model_restart(PATH, loss_array, data_info, nor_para)\n",
    "            print('OUTPUT is saved at: '+PATH)        \n",
    "            print_key_results(NNRTMC_solver[mi].predict(input_torch[ind_test,:])*rsdt_array[ind_test,None], \n",
    "                              output_array[ind_test,:]*rsdt_array[ind_test,None], \n",
    "                              nor_para)\n",
    "        lr_sta = 1e-4\n",
    "        print(f'{Exp_name} Finished: run {i}!')  \n",
    "        \n",
    "    print('All runs finished. Increase <run_num> if you need to continue to train the model.')\n",
    "\n",
    "    # # move slurm log to work dir\n",
    "    # job_id = int(os.environ[\"SLURM_JOB_ID\"])\n",
    "    # ossyscmd = f'cp slurm-{job_id}.out {exp_dir}/' \n",
    "    # print(ossyscmd)\n",
    "    # os.system(ossyscmd) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "673db8d1-3704-4fe3-90ca-e6b699015f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:03:04.993109Z",
     "iopub.status.busy": "2023-05-18T17:03:04.992730Z",
     "iopub.status.idle": "2023-05-18T17:03:04.998402Z",
     "shell.execute_reply": "2023-05-18T17:03:04.997981Z",
     "shell.execute_reply.started": "2023-05-18T17:03:04.993091Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3953be0-a1d8-4c06-b867-eaf0db32db75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:03:04.998916Z",
     "iopub.status.busy": "2023-05-18T17:03:04.998775Z",
     "iopub.status.idle": "2023-05-18T17:03:05.002608Z",
     "shell.execute_reply": "2023-05-18T17:03:05.002185Z",
     "shell.execute_reply.started": "2023-05-18T17:03:04.998902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1,\n",
       "   0.007389739155769348,\n",
       "   0.473214715719223,\n",
       "   0.024451809003949165,\n",
       "   2.383967161178589]],\n",
       " [[191,\n",
       "   0.006337405648082495,\n",
       "   0.44197341799736023,\n",
       "   0.0231848806142807,\n",
       "   2.3433401584625244]]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f618aeae-1758-49c3-8fd5-1fc929ee3611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:03:05.003105Z",
     "iopub.status.busy": "2023-05-18T17:03:05.002976Z",
     "iopub.status.idle": "2023-05-18T17:03:05.008383Z",
     "shell.execute_reply": "2023-05-18T17:03:05.007967Z",
     "shell.execute_reply.started": "2023-05-18T17:03:05.003092Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127a013e-f579-4876-a1fc-ddc94d780781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:03:05.009314Z",
     "iopub.status.busy": "2023-05-18T17:03:05.009185Z",
     "iopub.status.idle": "2023-05-18T17:03:05.015046Z",
     "shell.execute_reply": "2023-05-18T17:03:05.014611Z",
     "shell.execute_reply.started": "2023-05-18T17:03:05.009301Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tigress/cw55/work/2022_radi_nn/NN_AM4/work/',\n",
       " 'ens_AM4std_sw_cs_LiH4W256Relu_EY')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir,Exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14025229-1dc6-4203-8559-38a33e9a6a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:03:05.015534Z",
     "iopub.status.busy": "2023-05-18T17:03:05.015406Z",
     "iopub.status.idle": "2023-05-18T17:03:05.162785Z",
     "shell.execute_reply": "2023-05-18T17:03:05.162279Z",
     "shell.execute_reply.started": "2023-05-18T17:03:05.015521Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.01.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.02.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model0_restart.03.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.01.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.02.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model1_restart.03.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model2_restart.01.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model2_restart.02.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/model2_restart.03.pth\n",
      "/tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/NNRTMC_utils.py\n"
     ]
    }
   ],
   "source": [
    "ls /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e94c98-9a22-42c7-850d-e4d752cd823a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T17:03:05.163604Z",
     "iopub.status.busy": "2023-05-18T17:03:05.163446Z",
     "iopub.status.idle": "2023-05-18T17:03:05.318133Z",
     "shell.execute_reply": "2023-05-18T17:03:05.317506Z",
     "shell.execute_reply.started": "2023-05-18T17:03:05.163586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm -rf /tigress/cw55/work/2022_radi_nn/NN_AM4/work/ens_AM4std_sw_cs_LiH4W256Relu_EY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba672f57-1163-49ac-ac3b-03877fe263b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch20",
   "language": "python",
   "name": "pytorch20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
